{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, \\\n",
    "                            precision_recall_curve, average_precision_score, roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shap\n",
    "\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_loc = Path('/disks/data/datasets/ADNI/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(data_file_loc/'ADNI Data SPSS-CSV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['GENDER', 'maritalstatus', 'APOE4', 'ADASQ4_bl', 'DX', 'AGE', 'FDG_bl', 'CDRSB_bl', 'ADAS11_bl', 'ADAS13_bl', 'MMSE_bl', 'RAVLT_immediate_bl', 'RAVLT_learning_bl', 'RAVLT_forgetting_bl', 'RAVLT_perc_forgetting_bl', 'Ventricles_bl', 'Hippocampus_bl', 'WholeBrain_bl', 'Entorhinal_bl', 'Fusiform_bl', 'MidTemp_bl']"
      ],
      "text/plain": [
       "['GENDER',\n",
       " 'maritalstatus',\n",
       " 'APOE4',\n",
       " 'ADASQ4_bl',\n",
       " 'DX',\n",
       " 'AGE',\n",
       " 'FDG_bl',\n",
       " 'CDRSB_bl',\n",
       " 'ADAS11_bl',\n",
       " 'ADAS13_bl',\n",
       " 'MMSE_bl',\n",
       " 'RAVLT_immediate_bl',\n",
       " 'RAVLT_learning_bl',\n",
       " 'RAVLT_forgetting_bl',\n",
       " 'RAVLT_perc_forgetting_bl',\n",
       " 'Ventricles_bl',\n",
       " 'Hippocampus_bl',\n",
       " 'WholeBrain_bl',\n",
       " 'Entorhinal_bl',\n",
       " 'Fusiform_bl',\n",
       " 'MidTemp_bl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = list(raw_df.columns)\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENDER</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>ADASQ4_bl</th>\n",
       "      <th>DX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>FDG_bl</th>\n",
       "      <th>CDRSB_bl</th>\n",
       "      <th>ADAS11_bl</th>\n",
       "      <th>ADAS13_bl</th>\n",
       "      <th>...</th>\n",
       "      <th>RAVLT_immediate_bl</th>\n",
       "      <th>RAVLT_learning_bl</th>\n",
       "      <th>RAVLT_forgetting_bl</th>\n",
       "      <th>RAVLT_perc_forgetting_bl</th>\n",
       "      <th>Ventricles_bl</th>\n",
       "      <th>Hippocampus_bl</th>\n",
       "      <th>WholeBrain_bl</th>\n",
       "      <th>Entorhinal_bl</th>\n",
       "      <th>Fusiform_bl</th>\n",
       "      <th>MidTemp_bl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>MCI</td>\n",
       "      <td>78.6</td>\n",
       "      <td>1.318400</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>52877.00000</td>\n",
       "      <td>5941.000000</td>\n",
       "      <td>1051620.000</td>\n",
       "      <td>3278.00000</td>\n",
       "      <td>16249.00000</td>\n",
       "      <td>18784.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>83.7</td>\n",
       "      <td>1.228990</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.3333</td>\n",
       "      <td>30054.00000</td>\n",
       "      <td>6488.000000</td>\n",
       "      <td>905972.000</td>\n",
       "      <td>3491.00000</td>\n",
       "      <td>14554.00000</td>\n",
       "      <td>16551.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>CN</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1.173280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-10.0000</td>\n",
       "      <td>51558.00000</td>\n",
       "      <td>6969.000000</td>\n",
       "      <td>1064940.000</td>\n",
       "      <td>3303.00000</td>\n",
       "      <td>18820.00000</td>\n",
       "      <td>21969.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>CN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.227286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.67</td>\n",
       "      <td>19.67</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>40274.12831</td>\n",
       "      <td>6794.012692</td>\n",
       "      <td>1020753.123</td>\n",
       "      <td>3485.98162</td>\n",
       "      <td>17303.26072</td>\n",
       "      <td>19450.01906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>MCI</td>\n",
       "      <td>72.1</td>\n",
       "      <td>1.096340</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>32799.00000</td>\n",
       "      <td>6566.000000</td>\n",
       "      <td>1077770.000</td>\n",
       "      <td>2898.00000</td>\n",
       "      <td>19822.00000</td>\n",
       "      <td>21282.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GENDER maritalstatus  APOE4  ADASQ4_bl   DX   AGE    FDG_bl  CDRSB_bl  \\\n",
       "0  Female       Married      0          8  MCI  78.6  1.318400       1.5   \n",
       "1  Female       Widowed      0          4  MCI  83.7  1.228990       0.5   \n",
       "2  Female      Divorced      0          2   CN  68.5  1.173280       0.0   \n",
       "3  Female       Married      0          7   CN  67.0  1.227286       0.0   \n",
       "4    Male       Married      1          7  MCI  72.1  1.096340       0.5   \n",
       "\n",
       "   ADAS11_bl  ADAS13_bl  ...  RAVLT_immediate_bl  RAVLT_learning_bl  \\\n",
       "0       9.00      19.00  ...                40.0                6.0   \n",
       "1       8.00      12.00  ...                50.0                4.0   \n",
       "2       1.00       3.00  ...                53.0                3.0   \n",
       "3      10.67      19.67  ...                28.0                4.0   \n",
       "4      15.33      22.33  ...                27.0                4.0   \n",
       "\n",
       "   RAVLT_forgetting_bl  RAVLT_perc_forgetting_bl  Ventricles_bl  \\\n",
       "0                  9.0                   90.0000    52877.00000   \n",
       "1                  4.0                   33.3333    30054.00000   \n",
       "2                 -1.0                  -10.0000    51558.00000   \n",
       "3                  4.0                   50.0000    40274.12831   \n",
       "4                  7.0                  100.0000    32799.00000   \n",
       "\n",
       "   Hippocampus_bl  WholeBrain_bl  Entorhinal_bl  Fusiform_bl   MidTemp_bl  \n",
       "0     5941.000000    1051620.000     3278.00000  16249.00000  18784.00000  \n",
       "1     6488.000000     905972.000     3491.00000  14554.00000  16551.00000  \n",
       "2     6969.000000    1064940.000     3303.00000  18820.00000  21969.00000  \n",
       "3     6794.012692    1020753.123     3485.98162  17303.26072  19450.01906  \n",
       "4     6566.000000    1077770.000     2898.00000  19822.00000  21282.00000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shufle \n",
    "df = raw_df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CN', 1050), ('Dementia', 1050), ('MCI', 1050)]\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "df_resampled, y_resampled = ros.fit_resample(df, df.DX)\n",
    "\n",
    "# shufle \n",
    "df_resampled = df_resampled.sample(frac=1).reset_index(drop=True)\n",
    "df.head()\n",
    "\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APOE4</th>\n",
       "      <th>ADASQ4_bl</th>\n",
       "      <th>DX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>FDG_bl</th>\n",
       "      <th>CDRSB_bl</th>\n",
       "      <th>ADAS11_bl</th>\n",
       "      <th>ADAS13_bl</th>\n",
       "      <th>MMSE_bl</th>\n",
       "      <th>RAVLT_immediate_bl</th>\n",
       "      <th>...</th>\n",
       "      <th>WholeBrain_bl</th>\n",
       "      <th>Entorhinal_bl</th>\n",
       "      <th>Fusiform_bl</th>\n",
       "      <th>MidTemp_bl</th>\n",
       "      <th>GENDER_Female</th>\n",
       "      <th>GENDER_Male</th>\n",
       "      <th>maritalstatus_Divorced</th>\n",
       "      <th>maritalstatus_Married</th>\n",
       "      <th>maritalstatus_Never married</th>\n",
       "      <th>maritalstatus_Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>72.3</td>\n",
       "      <td>1.156400</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>30</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>871342.000</td>\n",
       "      <td>4119.00000</td>\n",
       "      <td>12430.00000</td>\n",
       "      <td>19215.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>CN</td>\n",
       "      <td>67.7</td>\n",
       "      <td>1.227286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.33</td>\n",
       "      <td>12.33</td>\n",
       "      <td>30</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1020753.123</td>\n",
       "      <td>3485.98162</td>\n",
       "      <td>17303.26072</td>\n",
       "      <td>19450.01906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CN</td>\n",
       "      <td>65.1</td>\n",
       "      <td>1.227286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>10.67</td>\n",
       "      <td>28</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1020753.123</td>\n",
       "      <td>3485.98162</td>\n",
       "      <td>17303.26072</td>\n",
       "      <td>19450.01906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>62.7</td>\n",
       "      <td>1.350600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>20</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012760.000</td>\n",
       "      <td>3592.00000</td>\n",
       "      <td>15906.00000</td>\n",
       "      <td>20834.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CN</td>\n",
       "      <td>69.2</td>\n",
       "      <td>1.227286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.33</td>\n",
       "      <td>8.33</td>\n",
       "      <td>29</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1020753.123</td>\n",
       "      <td>3485.98162</td>\n",
       "      <td>17303.26072</td>\n",
       "      <td>19450.01906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APOE4  ADASQ4_bl        DX   AGE    FDG_bl  CDRSB_bl  ADAS11_bl  ADAS13_bl  \\\n",
       "0      1          1       MCI  72.3  1.156400       1.5       9.00      11.00   \n",
       "1      0          3        CN  67.7  1.227286       0.0       9.33      12.33   \n",
       "2      0          0        CN  65.1  1.227286       0.0       9.67      10.67   \n",
       "3      0          5  Dementia  62.7  1.350600       2.0      18.00      27.00   \n",
       "4      1          1        CN  69.2  1.227286       0.0       5.33       8.33   \n",
       "\n",
       "   MMSE_bl  RAVLT_immediate_bl  ...  WholeBrain_bl  Entorhinal_bl  \\\n",
       "0       30                44.0  ...     871342.000     4119.00000   \n",
       "1       30                39.0  ...    1020753.123     3485.98162   \n",
       "2       28                57.0  ...    1020753.123     3485.98162   \n",
       "3       20                34.0  ...    1012760.000     3592.00000   \n",
       "4       29                58.0  ...    1020753.123     3485.98162   \n",
       "\n",
       "   Fusiform_bl   MidTemp_bl  GENDER_Female  GENDER_Male  \\\n",
       "0  12430.00000  19215.00000              1            0   \n",
       "1  17303.26072  19450.01906              1            0   \n",
       "2  17303.26072  19450.01906              1            0   \n",
       "3  15906.00000  20834.00000              1            0   \n",
       "4  17303.26072  19450.01906              1            0   \n",
       "\n",
       "   maritalstatus_Divorced  maritalstatus_Married  maritalstatus_Never married  \\\n",
       "0                       0                      0                            0   \n",
       "1                       0                      0                            1   \n",
       "2                       0                      1                            0   \n",
       "3                       0                      1                            0   \n",
       "4                       0                      1                            0   \n",
       "\n",
       "   maritalstatus_Widowed  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical columns to one-hot encodings\n",
    "df_ohe = pd.get_dummies(df_resampled, columns=['GENDER'])\n",
    "df_ohe = pd.get_dummies(df_ohe, columns=['maritalstatus'])\n",
    "# df_ohe.to_csv(\"df_ohe_1.csv\")\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the categorical and continuous columns\n",
    "cat_names = ['GENDER','maritalstatus']\n",
    "\n",
    "cont_names = col_names.copy()\n",
    "cont_names.remove('DX')\n",
    "cont_names.remove('GENDER')\n",
    "cont_names.remove('maritalstatus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 0.2677777777777778\n",
      "1.0 0.0 0.5528253968253971\n",
      "1.0 0.0 0.5166578589944241\n",
      "1.0 0.0 0.5088865716676555\n",
      "1.0 0.0 0.19707936507936527\n",
      "1.0 0.0 0.29255932503338433\n",
      "1.0 0.0 0.34945482819647955\n",
      "1.0 0.0 0.7397802197802159\n",
      "1.0 0.0 0.48437793452054545\n",
      "1.0 0.0 0.6016187167845409\n",
      "1.0 0.0 0.7503860574516218\n",
      "1.0 0.0 0.9211495273587036\n",
      "1.0 0.0 0.25616977416223613\n",
      "1.0 0.0 0.47146586246889555\n",
      "1.0 0.0 0.421775030454858\n",
      "1.0 0.0 0.4436539257796131\n",
      "1.0 0.0 0.3864384272338237\n",
      "1.0 0.0 0.42940292400822694\n"
     ]
    }
   ],
   "source": [
    "# normalize the continuous columns\n",
    "for cont_name in cont_names:\n",
    "    df_ohe[cont_name] = (df_ohe[cont_name] - min(df_ohe[cont_name]) )/(max(df_ohe[cont_name]) - min(df_ohe[cont_name]))\n",
    "\n",
    "# verify that columns are normalized\n",
    "for cont_name in cont_names:\n",
    "    print(max(df_ohe[cont_name]), min(df_ohe[cont_name]), np.mean(df_ohe[cont_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 1050, 1050)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_ohe.to_csv(\"df_ohe_2.csv\")\n",
    "df_ohe.DX.value_counts()['CN'], df_ohe.DX.value_counts()['MCI'], df_ohe.DX.value_counts()['Dementia']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights = compute_sample_weight(class_weight='balanced', y=df_ohe.DX)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes = np.unique(df_ohe.DX), y=df_ohe.DX)\n",
    "\n",
    "class_weights_dict_label = dict(zip(np.unique(df_ohe.DX),class_weights))\n",
    "class_weights_dict_label_enc = dict(zip(range(3),class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets for binary classifications\n",
    "\n",
    "# df_ohe_CN_Demen = df_ohe.loc[df['DX'].isin(['CN','Dementia'])]\n",
    "# df_ohe_MCI_Demen = df_ohe.loc[df['DX'].isin(['MCI','Dementia'])]\n",
    "# df_ohe_CN_MCI = df_ohe.loc[df['DX'].isin(['CN','MCI'])]\n",
    "# # verify label-reassignment\n",
    "# print(df_ohe_CN_Demen['DX'].unique(), df_ohe_MCI_Demen['DX'].unique(), df_ohe_CN_MCI['DX'].unique())\n",
    "\n",
    "# # datasets for one vs all classifications\n",
    "# df_ohe_CN_vs_all = df_ohe.copy()\n",
    "# df_ohe_CN_vs_all = df_ohe_CN_vs_all.replace(['MCI','Dementia'],'Non')\n",
    "\n",
    "# df_ohe_MCI_vs_all = df_ohe.copy()\n",
    "# df_ohe_MCI_vs_all = df_ohe_MCI_vs_all.replace(['CN','Dementia'],'Non')\n",
    "\n",
    "# df_ohe_Demen_vs_all = df_ohe.copy()\n",
    "# df_ohe_Demen_vs_all = df_ohe_Demen_vs_all.replace(['CN','MCI'],'Non')\n",
    "\n",
    "# # verify label-reassignment\n",
    "# print(df_ohe_CN_vs_all['DX'].unique(), df_ohe_MCI_vs_all['DX'].unique(), df_ohe_Demen_vs_all['DX'].unique())\n",
    "\n",
    "class Metrics:\n",
    "    \n",
    "    def __init__(self, benchmark_acc = None, benchmark_f1 = None, benchmark_spec = None, benchmark_sen = None, benchmark_auc = None, benchmark_mcc = None):\n",
    "        self.b_accuracy = benchmark_acc\n",
    "        self.b_f1 = benchmark_f1\n",
    "        self.b_sensitivity = benchmark_sen\n",
    "        self.b_specificity = benchmark_spec\n",
    "        self.b_auc_roc = benchmark_auc\n",
    "        self.b_mcc = benchmark_mcc\n",
    "        \n",
    "    def reset_history(self):\n",
    "        self.accuracies = []\n",
    "        self.f1s = []\n",
    "        self.recalls = []\n",
    "        self.precisions = []\n",
    "        self.sensitivity = []\n",
    "        self.specificity = []\n",
    "        self.auc_roc = []        \n",
    "        self.tp_tn_fp_fn = []\n",
    "        self.mcc = []\n",
    "\n",
    "        \n",
    "    metrics_names = ('acc','mcc',)# 'specificity', 'sensitivity', 'f1_score', 'auc_roc', 'recall', \n",
    "                     #'precision', 'mcc',  'tp','fp','tn','fn')\n",
    "    @classmethod\n",
    "    def compute_mcc(cls, y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        mcc = (tp*tn - fp*fn) / (np.sqrt(  (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)  ) + 1e-8) \n",
    "        return mcc\n",
    "    \n",
    "    @classmethod\n",
    "    def compute_sensitivity(cls, y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        sensitivity = tp/(tp+fn)\n",
    "        return sensitivity\n",
    "    \n",
    "    @classmethod\n",
    "    def compute_specificity(cls, y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn/(fp+tn)\n",
    "        return specificity\n",
    "    \n",
    "    @classmethod\n",
    "    def compute_accuracy(cls, y_true, y_pred):\n",
    "        accuracy = (y_true==y_pred).sum()/len(y_true)\n",
    "        return accuracy\n",
    "    \n",
    "    def compute_metrics(self, y_true, y_pred, label_list, epoch, do_print = False, store_vals = False):\n",
    "        accuracy = (y_true==y_pred).sum()/len(y_true)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        \n",
    "#         cm = confusion_matrix(y_true, y_pred, labels = label_list)\n",
    "\n",
    "#         tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "#         specificity = tn/(fp+tn)\n",
    "#         sensitivity = tp/(tp+fn)\n",
    "#         f1 = f1_score(y_true, y_pred)\n",
    "#         recall = recall_score(y_true, y_pred)\n",
    "#         precision = precision_score(y_true, y_pred)\n",
    "#         auc_roc = roc_auc_score( y_true, y_pred )  \n",
    "#         mcc = (tp*tn - fp*fn) / (np.sqrt(  (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)  ) + 1e-8) \n",
    "        \n",
    "        metrics_vals = ( accuracy, mcc, )# specificity, sensitivity, f1, auc_roc, recall, precision, mcc, tp, fp, tn, fn )\n",
    "\n",
    "        results = ( metrics_names, metrics_vals )        \n",
    "        \n",
    "        return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_names = Metrics.metrics_names\n",
    "# clf_metrics = [ i+'_'+j for j in metrics_names for i in classifier_namelist+NN_labels ]\n",
    "# clf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# np.array([[1,2],[3,4]]).transpose().reshape(1,-1)\n",
    "# tmp, inner_CV_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CN', 'Dementia', 'MCI'], dtype=object),\n",
       " array(['CN', 'Dementia', 'MCI'], dtype=object),\n",
       " ['CN', 'Dementia', 'MCI'],\n",
       " array([ True]),\n",
       " {0: 'CN', 1: 'Dementia', 2: 'MCI'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_params = [ #{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': 0, 'learning_rate_init': 0.2},\n",
    "              #{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9, 'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "              #{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9, 'nesterovs_momentum': True, 'learning_rate_init': 0.2},\n",
    "              #{'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': 0, 'learning_rate_init': 0.2},\n",
    "              #{'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9, 'nesterovs_momentum': True, 'learning_rate_init': 0.2},\n",
    "              #{'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9, 'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "              {'solver': 'adam', 'learning_rate_init': 0.01},\n",
    "              #{'solver': 'adam', 'learning_rate': 'invscaling', 'learning_rate_init': 0.01}\n",
    "            ]\n",
    "\n",
    "\n",
    "NN_labels = [ #\"constant learning-rate\", \n",
    "              #\"constant with momentum\",\n",
    "              #\"constant with Nesterov's momentum\",\n",
    "              #\"inv-scaling learning-rate\", \n",
    "              #\"inv-scaling with momentum\",\n",
    "              #\"inv-scaling with Nesterov's momentum\", \n",
    "              \"NN_Adam\",\n",
    "             # \"NN_Adam_inv_scaling_LR\"\n",
    "            ]\n",
    "\n",
    "NN_max_iter = 100\n",
    "\n",
    "lgb_params  = {\n",
    "          \"objective\" : \"multiclass\",\n",
    "          \"num_class\" : 4,\n",
    "          \"num_leaves\" : 60,\n",
    "          \"max_depth\": -1,\n",
    "          \"learning_rate\" : 0.01,\n",
    "          \"bagging_fraction\" : 0.9,  # subsample\n",
    "          \"feature_fraction\" : 0.9,  # colsample_bytree\n",
    "          \"bagging_freq\" : 5,        # subsample_freq\n",
    "          \"bagging_seed\" : 2018,\n",
    "          \"verbosity\" : -1 }\n",
    "\n",
    "\n",
    "classifier_namelist = [ \"RF\", \"SVM\", \"LDA\", \"XGBoost\", \"LightGBM\"]\n",
    "\n",
    "\n",
    "# setup inner and outer k-fold \n",
    "skf_outer = StratifiedKFold(n_splits = 10)\n",
    "skf_inner = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "# drop the target column \n",
    "X = (\n",
    "        df_ohe\n",
    "        .drop(['DX'], axis=1)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# the target column\n",
    "y = df_ohe.DX\n",
    "label_list = sorted(y.unique()) \n",
    "\n",
    "# label encode the target variable\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "\n",
    "y_label_enc = le.transform(y)\n",
    "y_inv = le.inverse_transform(y_label_enc)\n",
    "\n",
    "y_str = y\n",
    "y = y_label_enc \n",
    "\n",
    "#le.classes_, (y_inv==y).unique()\n",
    "\n",
    "metrics = Metrics()\n",
    "metrics_names = Metrics.metrics_names\n",
    "\n",
    "class_idx_to_name = dict(zip(range(len(le.classes_)),le.classes_))\n",
    "\n",
    "\n",
    "np.unique(df_ohe.DX), le.classes_, label_list, (y_str==y_inv).unique(), class_idx_to_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(X)), np.all(np.isfinite(X)), type(df_ohe)\n",
    "#df_ohe.to_csv(\"df_ohe.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_shap_plots(model, X_test, class_idx_to_name):\n",
    "    \n",
    "    if (isinstance(model, RandomForestClassifier)):\n",
    "        \n",
    "        return \n",
    "    \n",
    "        start_time_shap = time.time()\n",
    "        explainer = shap.KernelExplainer(model.predict_proba, X_test)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", module=\"shap\")\n",
    "            shap_values = explainer.shap_values(X_test, nsamples = 40) #nsamples='auto')\n",
    "\n",
    "        end_time_shap = time.time()\n",
    "        print(f'Shap Elapsed Time: {end_time_shap - start_time_shap}')\n",
    "                \n",
    "        f = plt.figure()\n",
    "        shap.summary_plot(shap_values, X_test)\n",
    "        f.savefig(\"figs/rf/summary_plot_rf.png\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "        # plot the SHAP values for the Setosa output of the first instance\n",
    "        shap.force_plot(explainer.expected_value[0], shap_values[0][0,:], X_test.iloc[0,:], link=\"logit\")\n",
    "        \n",
    "        for class_idx, _ in enumerate(class_idx_to_name.keys()):\n",
    "            #f = plt.figure()\n",
    "            shap.force_plot(explainer.expected_value[class_idx], shap_values[class_idx], X_test)\n",
    "            #f.savefig(f\"figs/rf/force_plot_rf_{class_idx}_{class_idx_to_name[class_idx]}.png\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "        for class_idx, _ in enumerate(class_idx_to_name.keys()):\n",
    "            for colname in X_test.columns:\n",
    "                #f = plt.figure()\n",
    "                shap.dependence_plot(colname, shap_values[class_idx], X_test)   \n",
    "                #f.savefig(f\"figs/rf/dependence_plot_rf_{class_idx}_{class_idx_to_name[class_idx]}_col-{colname}.png\", bbox_inches='tight', dpi=600)       \n",
    "        \n",
    "    elif (isinstance(model, svm.SVC)):\n",
    "        \n",
    "        return\n",
    "    \n",
    "        start_time_shap = time.time()\n",
    "        explainer = shap.KernelExplainer(model.predict_proba, X_test, link=\"logit\")\n",
    "    \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", module=\"shap\")\n",
    "            shap_values = explainer.shap_values(X_test, nsamples = 30)\n",
    "\n",
    "        end_time_shap = time.time()\n",
    "        print(f'Shap Elapsed Time: {end_time_shap - start_time_shap}')\n",
    "\n",
    "        f = plt.figure()\n",
    "        shap.summary_plot(shap_values, X_test)\n",
    "        f.savefig(\"figs/svm/summary_plot_svm.png\", bbox_inches='tight', dpi=600)\n",
    "        \n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            #f = plt.figure()\n",
    "            shap.force_plot(explainer.expected_value[class_idx], shap_values[class_idx], X_test)\n",
    "            #f.savefig(f\"figs/svm/force_plot_svm_{class_idx}_{class_idx_to_name[class_idx]}.png\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            for colname in X_test.columns:\n",
    "                #f = plt.figure()\n",
    "                shap.dependence_plot(colname, shap_values[class_idx], X_test)   \n",
    "                #f.savefig(f\"figs/svm/dependence_plot_svm_{class_idx}_{class_idx_to_name[class_idx]}_col-{colname}.png\", bbox_inches='tight', dpi=600)              \n",
    "        \n",
    "    elif (isinstance(model, LinearDiscriminantAnalysis)):\n",
    "        return\n",
    "    \n",
    "        start_time_shap = time.time()\n",
    "        explainer = shap.KernelExplainer(model.predict_proba, X_test, link=\"logit\")\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", module=\"shap\")\n",
    "            shap_values = explainer.shap_values(X_test, nsamples=100)\n",
    "\n",
    "        end_time_shap = time.time()\n",
    "        print(f'Shap Elapsed Time: {end_time_shap - start_time_shap}')\n",
    "\n",
    "        f = plt.figure()\n",
    "        shap.summary_plot(shap_values, X_test)\n",
    "        f.savefig(\"figs/lda/summary_plot_lda.png\", bbox_inches='tight', dpi=600)    \n",
    "        \n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            #f = plt.figure()\n",
    "            shap.force_plot(explainer.expected_value[class_idx], shap_values[class_idx], X_test)\n",
    "            #f.savefig(f\"figs/lda/force_plot_lda_{class_idx}_{class_idx_to_name[class_idx]}.png\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            for colname in X_test.columns:\n",
    "                #f = plt.figure()\n",
    "                shap.dependence_plot(colname, shap_values[class_idx], X_test)   \n",
    "                #f.savefig(f\"figs/lda/dependence_plot_lda_{class_idx}_{class_idx_to_name[class_idx]}_col-{colname}.png\", bbox_inches='tight', dpi=600)         \n",
    "        \n",
    "        \n",
    "    elif (isinstance(model, xgboost.XGBClassifier)):\n",
    "        return\n",
    "    \n",
    "        start_time_shap = time.time()\n",
    "        explainer = shap.TreeExplainer(xgb)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", module=\"shap\")\n",
    "            shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "        end_time_shap = time.time()\n",
    "        print(f'Shap Elapsed Time: {end_time_shap - start_time_shap}')\n",
    "\n",
    "        f = plt.figure()\n",
    "        shap.summary_plot(shap_values, X_test)\n",
    "        f.savefig(\"figs/xgboost/summary_plot_xgboost.png\", bbox_inches='tight', dpi=600)  \n",
    "\n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            #f = plt.figure()\n",
    "            shap.force_plot(explainer.expected_value[class_idx], shap_values[class_idx], X_test)\n",
    "            #f.savefig(f\"figs/xgboost/force_plot_xgboost_{class_idx}_{class_idx_to_name[class_idx]}.png\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            for colname in X_test.columns:\n",
    "                #f = plt.figure()\n",
    "                shap.dependence_plot(colname, shap_values[class_idx], X_test)   \n",
    "                #f.savefig(f\"figs/xgboost/dependence_plot_xgboost_{class_idx}_{class_idx_to_name[class_idx]}_col-{colname}.png\", bbox_inches='tight', dpi=600)         \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif (isinstance(model, lgb.LGBMClassifier)):\n",
    "        return\n",
    "    \n",
    "        start_time_shap = time.time()\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", module=\"shap\")\n",
    "            shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "        end_time_shap = time.time()\n",
    "        print(f'Shap Elapsed Time: {end_time_shap - start_time_shap}')\n",
    "\n",
    "        f = plt.figure()\n",
    "        shap.summary_plot(shap_values, X_test)\n",
    "        f.savefig(\"figs/lightGBM/summary_plot_lightGBM.png\", bbox_inches='tight', dpi=600) \n",
    "        \n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            #f = plt.figure()\n",
    "            shap.force_plot(explainer.expected_value[class_idx], shap_values[class_idx], X_test)\n",
    "            #f.savefig(f\"figs/lightGBM/force_plot_lightGBM_{class_idx}_{class_idx_to_name[class_idx]}.png\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            for colname in X_test.columns:\n",
    "                #f = plt.figure()\n",
    "                shap.dependence_plot(colname, shap_values[class_idx], X_test)   \n",
    "                #f.savefig(f\"figs/lightGBM/dependence_plot_lightGBM_{class_idx}_{class_idx_to_name[class_idx]}_col-{colname}.png\", bbox_inches='tight', dpi=600)             \n",
    "    \n",
    "    elif (isinstance(model, MLPClassifier)):\n",
    "        \n",
    "        start_time_shap = time.time()\n",
    "        explainer = shap.KernelExplainer(model.predict_proba, X_test)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", module=\"shap\")\n",
    "            shap_values = explainer.shap_values(X_test, nsamples=80)\n",
    "\n",
    "        end_time_shap = time.time()\n",
    "        print(f'Shap Elapsed Time: {end_time_shap - start_time_shap}')\n",
    "\n",
    "        f = plt.figure()\n",
    "        shap.summary_plot(shap_values, X_test)\n",
    "        f.savefig(\"figs/NN/summary_plot_NN.png\", bbox_inches='tight', dpi=600) \n",
    "        \n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            #f = plt.figure()\n",
    "            shap.force_plot(explainer.expected_value[class_idx], shap_values[class_idx], X_test)\n",
    "            #f.savefig(f\"figs/NN/force_plot_NN_{class_idx}_{class_idx_to_name[class_idx]}.png\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "        for class_idx in class_idx_to_name.keys():\n",
    "            for colname in X_test.columns:\n",
    "                #f = plt.figure()\n",
    "                shap.dependence_plot(colname, shap_values[class_idx], X_test)   \n",
    "                #f.savefig(f\"figs/NN/dependence_plot_NN_{class_idx}_{class_idx_to_name[class_idx]}_col-{colname}.png\", bbox_inches='tight', dpi=600)             \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "<class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "  RF_acc  SVM_acc  LDA_acc  XGBoost_acc  LightGBM_acc  NN_Adam_acc   RF_mcc  SVM_mcc  LDA_mcc  XGBoost_mcc  LightGBM_mcc  NN_Adam_mcc\n",
      "0.930159 0.873016 0.819048     0.942857      0.926984     0.914286 0.897248 0.811440 0.729974     0.915158      0.891056     0.872392\tElapsed time: 26.23685884475708\n",
      "0.926984 0.853968 0.815873 0.933333 0.885714 0.876190 0.892462 0.782278 0.723985 0.900340 0.828722 0.814323\tElapsed time: 24.89910364151001\n",
      "0.946032 0.873016 0.819048 0.946032 0.917460 0.901587 0.920482 0.814127 0.730662 0.920398 0.876840 0.854918\tElapsed time: 24.96433115005493\n",
      "0.955556 0.866667 0.806349 0.958730 0.917460 0.911111 0.934068 0.802772 0.709814 0.939047 0.876230 0.867546\tElapsed time: 24.536574363708496\n",
      "0.958730 0.885714 0.838095 0.968254 0.955556 0.936508 0.938450 0.830734 0.757223 0.952511 0.933517 0.905104\tElapsed time: 27.198167324066162\n",
      "0.949206 0.892063 0.847619 0.958730 0.939683 0.933333 0.924537 0.841781 0.775673 0.938365 0.909565 0.900122\tElapsed time: 27.05614185333252\n",
      "0.965079 0.892063 0.841270 0.968254 0.939683 0.926984 0.947805 0.840245 0.764091 0.952424 0.910571 0.890597\tElapsed time: 26.200366020202637\n",
      "0.933333 0.869841 0.850794 0.952381 0.920635 0.933333 0.902473 0.809190 0.780247 0.930359 0.881366 0.900504\tElapsed time: 29.31944704055786\n",
      "0.961905 0.882540 0.841270 0.961905 0.936508 0.933333 0.942985 0.824745 0.762782 0.943028 0.905803 0.900422\tElapsed time: 24.1188702583313\n",
      "0.955556 0.885714 0.847619 0.965079 0.933333 0.917460 0.933771 0.831797 0.771989 0.947891 0.900122 0.877957\tElapsed time: 22.68249535560608\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "\n",
    "all_CV_results = []\n",
    "all_CV_confusion_mats = []\n",
    "\n",
    "clf_metrics_labels = [ i+'_'+j for j in metrics_names for i in classifier_namelist+NN_labels ]\n",
    "\n",
    "outer_CV_results_df = pd.DataFrame({**dict.fromkeys(clf_metrics_labels, [])})\n",
    "outer_CV_confusion_mats = []\n",
    "\n",
    "show_header = True\n",
    "\n",
    "outer_fold_idx = 0\n",
    "\n",
    "# outer k-fold (for generalization performance estimation)\n",
    "for train_idx_outer, test_idx_outer in skf_outer.split(X, y):\n",
    "\n",
    "    outer_fold_idx += 1\n",
    "    \n",
    "    X_train_outer = X.iloc[train_idx_outer]\n",
    "    y_train_outer = y[train_idx_outer]\n",
    "    sample_weights_train_outer = sample_weights[train_idx_outer]\n",
    "    \n",
    "    X_test_outer = X.iloc[test_idx_outer]\n",
    "    y_test_outer = y[test_idx_outer]  \n",
    "    #class_weights_test_outer = sample_weights[test_idx_outer]\n",
    "    \n",
    "    inner_split_idx = 0\n",
    "    \n",
    "    # dataframe for holding the results from all the inner folds for all the candidate classifiers \n",
    "    inner_CV_results_df = pd.DataFrame({**dict.fromkeys(clf_metrics_labels, []) })\n",
    "    inner_CV_fold_conf_mats = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # inner k-fold (for comparing model performance/hyper parameter tuning)\n",
    "    for train_idx_inner, test_idx_inner in skf_inner.split(X_train_outer, y_train_outer):\n",
    "        \n",
    "        inner_split_idx +=1\n",
    "        \n",
    "        # inner fold's trainset\n",
    "        X_train_inner = X_train_outer.iloc[train_idx_inner]\n",
    "        y_train_inner = y_train_outer[train_idx_inner]\n",
    "        sample_weights_train_inner = sample_weights_train_outer[train_idx_inner]\n",
    "\n",
    "\n",
    "        # inner fold's testset\n",
    "        X_test_inner = X_train_outer.iloc[test_idx_inner]\n",
    "        y_test_inner = y_train_outer[test_idx_inner]\n",
    "        #sample_weights_test_inner = sample_weights_train_outer[test_idx_inner]\n",
    "        \n",
    "        \n",
    "        # initialize the classifiers\n",
    "        rf_clf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)#, class_weight = class_weights_dict_label_enc)\n",
    "        svm_clf = svm.SVC(kernel='rbf', probability=True)#, class_weight = class_weights_dict_label_enc)\n",
    "        lda_clf = LinearDiscriminantAnalysis()\n",
    "        xgb = xgboost.XGBClassifier()\n",
    "        lgb_clf = lgb.LGBMClassifier(**lgb_params)\n",
    "        \n",
    "        # list of classifiers to iterate over (except for NN)\n",
    "        classifiers = [rf_clf, svm_clf, lda_clf, xgb, lgb_clf ]\n",
    "\n",
    "        # add the NNs to the list    \n",
    "        for NN_config in NN_params:\n",
    "            classifiers.append(MLPClassifier(alpha=1e-5, hidden_layer_sizes=(100, 75, 25, 16), random_state=1, **NN_config))\n",
    "        \n",
    "        # to hold the results from the classifiers in each inner fold        \n",
    "        clf_results_inner_fold = []\n",
    "        clf_conf_mats_inner_fold = []\n",
    "        \n",
    "        # iterate over the classifiers to compute their performance on a specific inner fold\n",
    "        for clf in classifiers:\n",
    "            \n",
    "            #print(type(clf))\n",
    "            \n",
    "            #mean_acc = 0.0\n",
    "            \n",
    "            # some parameter combinations will not converge as can be seen on the\n",
    "            # plots so they are ignored here\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                                        module=\"sklearn\")\n",
    "            \n",
    "                # train the candidate classifier\n",
    "                #if (isinstance(clf, xgboost.XGBClassifier)):\n",
    "                #    clf.fit(X_train_inner, y_train_inner, sample_weight = sample_weights_train_inner)\n",
    "                #else:\n",
    "                clf.fit(X_train_inner, y_train_inner)\n",
    "\n",
    "            #y_pred_probs = clf.predict_proba(X_test_inner)\n",
    "            #y_pred_probs = clf.predict_proba(X_test.iloc[0:1])\n",
    "            y_pred_inner = clf.predict(X_test_inner)\n",
    "\n",
    "            # compute the mean accuracy\n",
    "            # mean_acc = clf.score(X_test_inner, y_test_inner)\n",
    "\n",
    "            _, results_metrics = metrics.compute_metrics(y_test_inner, y_pred_inner, label_list, -1)\n",
    "            confusion_mat = confusion_matrix(y_test_inner, y_pred_inner)\n",
    "            \n",
    "\n",
    "            # store the result from the classifier for this inner fold\n",
    "            clf_results_inner_fold.append(results_metrics)\n",
    "            clf_conf_mats_inner_fold.append(confusion_mat)\n",
    "        \n",
    "        # create a tmp dataframe containing the results from different classifiers on this inner fold\n",
    "        #tmp = pd.DataFrame([clf_results_inner_fold], columns=[*classifier_namelist, *NN_labels] )\n",
    "        tmp = pd.DataFrame(np.array(clf_results_inner_fold).transpose().reshape(1,-1), columns=inner_CV_results_df.columns )        \n",
    "        \n",
    "        # update the results\n",
    "        inner_CV_results_df = inner_CV_results_df.append(tmp)\n",
    "        inner_CV_fold_conf_mats.append(clf_conf_mats_inner_fold)\n",
    "        \n",
    "    # store the result for the outer fold\n",
    "    all_CV_results.append(inner_CV_results_df)       \n",
    "    all_CV_confusion_mats.append(inner_CV_fold_conf_mats)\n",
    "    \n",
    "    \n",
    "    # for re-training the classifiers on the outer fold's entire trainset\n",
    "    # initialize the classifiers\n",
    "    rf_clf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42, class_weight = class_weights_dict_label_enc)\n",
    "    svm_clf = svm.SVC(kernel='rbf', probability=True, class_weight = class_weights_dict_label_enc)\n",
    "    lda_clf = LinearDiscriminantAnalysis()\n",
    "    xgb = xgboost.XGBClassifier()\n",
    "    lgb_clf = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "    # list of classifiers to iterate over (except for NN)\n",
    "    classifiers = [rf_clf, svm_clf, lda_clf, xgb, lgb_clf ]\n",
    "\n",
    "    # add the NNs to the list    \n",
    "    for NN_config in NN_params:\n",
    "        classifiers.append(MLPClassifier(alpha=1e-5, hidden_layer_sizes=(100, 75, 25, 16), random_state=1, **NN_config))\n",
    "    \n",
    "    # to hold the results from the classifiers in each outer fold        \n",
    "    clf_results_outer_fold = []\n",
    "    confusion_mats_outer_fold = []    \n",
    "        \n",
    "    for clf in classifiers:\n",
    "\n",
    "        mean_acc = 0.0\n",
    "            \n",
    "        # some parameter combinations will not converge as can be seen on the\n",
    "        # plots so they are ignored here\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                                    module=\"sklearn\")\n",
    "            # train the candidate classifier\n",
    "            #if (isinstance(clf, xgboost.XGBClassifier)):\n",
    "            #    clf.fit(X_train_inner, y_train_inner, sample_weight = sample_weights_train_inner)\n",
    "            #else:\n",
    "            clf.fit(X_train_inner, y_train_inner)\n",
    "            \n",
    "            #y_pred_probs = clf.predict_proba(X_test_outer)\n",
    "            #y_pred_probs = clf.predict_proba(X_test.iloc[0:1])\n",
    "            y_pred_outer = clf.predict(X_test_outer)\n",
    "\n",
    "            # compute the mean accuracy\n",
    "            # mean_acc = clf.score(X_test_inner, y_test_inner)\n",
    "\n",
    "            #print()\n",
    "            _, results_metrics = metrics.compute_metrics(y_test_outer, y_pred_outer, label_list, -1)\n",
    "            outer_confusion_mat = confusion_matrix(y_test_outer, y_pred_outer)\n",
    "            \n",
    "            if (outer_fold_idx == 1):\n",
    "                print(type(clf))\n",
    "                #save_shap_plots(clf, X_test_outer, class_idx_to_name)\n",
    "                 \n",
    "                    \n",
    "            #print()\n",
    "\n",
    "        # store the result from the classifier for this inner fold\n",
    "        clf_results_outer_fold.append(results_metrics)\n",
    "        confusion_mats_outer_fold.append(outer_confusion_mat)\n",
    "    \n",
    "                    \n",
    "    #tmp = pd.DataFrame([clf_results_outer_fold], columns=[*classifier_namelist, *NN_labels] )\n",
    "    tmp = pd.DataFrame(np.array(clf_results_outer_fold).transpose().reshape(1,-1), columns=outer_CV_results_df.columns )\n",
    "    \n",
    "    outer_CV_results_df = outer_CV_results_df.append(tmp)\n",
    "    outer_CV_confusion_mats.append(confusion_mats_outer_fold)\n",
    "    \n",
    "    print(outer_CV_results_df.tail(1).to_string(index=False, header= show_header), end=\"\\t\")\n",
    "    show_header = False\n",
    "\n",
    "    #print(outer_CV_results_df.iloc[-1])\n",
    "    end_time = time.time()\n",
    "    print(f'Elapsed time: {end_time-start_time}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "XGBClassifier\n",
      "XGBClassifier\n",
      "XGBClassifier\n",
      "XGBClassifier\n",
      "XGBClassifier\n",
      "XGBClassifier\n",
      "XGBClassifier\n",
      "XGBClassifier\n",
      "XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "# Find which classifier performed best in each outer fold\n",
    "for all_CV_result in all_CV_results:\n",
    "    print(type(classifiers[np.argmax(all_CV_result.mean(axis = 0))]).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer_CV_confusion_mats_np.shape: (10, 6, 3, 3)\n",
      "[[102.    0.    3. ]\n",
      " [  0.  103.4   1.6]\n",
      " [  3.    6.4  95.6]]\n",
      "[[97.14285714  0.          2.85714286]\n",
      " [ 0.         98.47619048  1.52380952]\n",
      " [ 2.85714286  6.0952381  91.04761905]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix of selected classifier averaged across outer folds \n",
    "selected_classifier_idx = 3\n",
    "outer_CV_confusion_mats_np = np.array(outer_CV_confusion_mats)\n",
    "print('outer_CV_confusion_mats_np.shape:',outer_CV_confusion_mats_np.shape)\n",
    "conf_mat_freq_meaned = outer_CV_confusion_mats_np[:,selected_classifier_idx,:,:].mean(axis = 0)\n",
    "print(conf_mat_freq_meaned)\n",
    "conf_mat_pct_meaned = conf_mat_freq_meaned/conf_mat_freq_meaned.sum(axis =1)*100\n",
    "print(conf_mat_pct_meaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_acc</th>\n",
       "      <th>SVM_acc</th>\n",
       "      <th>LDA_acc</th>\n",
       "      <th>XGBoost_acc</th>\n",
       "      <th>LightGBM_acc</th>\n",
       "      <th>NN_Adam_acc</th>\n",
       "      <th>RF_mcc</th>\n",
       "      <th>SVM_mcc</th>\n",
       "      <th>LDA_mcc</th>\n",
       "      <th>XGBoost_mcc</th>\n",
       "      <th>LightGBM_mcc</th>\n",
       "      <th>NN_Adam_mcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.926984</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.897248</td>\n",
       "      <td>0.811440</td>\n",
       "      <td>0.729974</td>\n",
       "      <td>0.915158</td>\n",
       "      <td>0.891056</td>\n",
       "      <td>0.872392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926984</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.892462</td>\n",
       "      <td>0.782278</td>\n",
       "      <td>0.723985</td>\n",
       "      <td>0.900340</td>\n",
       "      <td>0.828722</td>\n",
       "      <td>0.814323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946032</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.946032</td>\n",
       "      <td>0.917460</td>\n",
       "      <td>0.901587</td>\n",
       "      <td>0.920482</td>\n",
       "      <td>0.814127</td>\n",
       "      <td>0.730662</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.876840</td>\n",
       "      <td>0.854918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.806349</td>\n",
       "      <td>0.958730</td>\n",
       "      <td>0.917460</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.934068</td>\n",
       "      <td>0.802772</td>\n",
       "      <td>0.709814</td>\n",
       "      <td>0.939047</td>\n",
       "      <td>0.876230</td>\n",
       "      <td>0.867546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958730</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.938450</td>\n",
       "      <td>0.830734</td>\n",
       "      <td>0.757223</td>\n",
       "      <td>0.952511</td>\n",
       "      <td>0.933517</td>\n",
       "      <td>0.905104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.949206</td>\n",
       "      <td>0.892063</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.958730</td>\n",
       "      <td>0.939683</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.924537</td>\n",
       "      <td>0.841781</td>\n",
       "      <td>0.775673</td>\n",
       "      <td>0.938365</td>\n",
       "      <td>0.909565</td>\n",
       "      <td>0.900122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.965079</td>\n",
       "      <td>0.892063</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.939683</td>\n",
       "      <td>0.926984</td>\n",
       "      <td>0.947805</td>\n",
       "      <td>0.840245</td>\n",
       "      <td>0.764091</td>\n",
       "      <td>0.952424</td>\n",
       "      <td>0.910571</td>\n",
       "      <td>0.890597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.850794</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.902473</td>\n",
       "      <td>0.809190</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.930359</td>\n",
       "      <td>0.881366</td>\n",
       "      <td>0.900504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.882540</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.942985</td>\n",
       "      <td>0.824745</td>\n",
       "      <td>0.762782</td>\n",
       "      <td>0.943028</td>\n",
       "      <td>0.905803</td>\n",
       "      <td>0.900422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.965079</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.917460</td>\n",
       "      <td>0.933771</td>\n",
       "      <td>0.831797</td>\n",
       "      <td>0.771989</td>\n",
       "      <td>0.947891</td>\n",
       "      <td>0.900122</td>\n",
       "      <td>0.877957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RF_acc  SVM_acc  LDA_acc  XGBoost_acc  LightGBM_acc  NN_Adam_acc   RF_mcc  \\\n",
       "0 0.930159 0.873016 0.819048     0.942857      0.926984     0.914286 0.897248   \n",
       "0 0.926984 0.853968 0.815873     0.933333      0.885714     0.876190 0.892462   \n",
       "0 0.946032 0.873016 0.819048     0.946032      0.917460     0.901587 0.920482   \n",
       "0 0.955556 0.866667 0.806349     0.958730      0.917460     0.911111 0.934068   \n",
       "0 0.958730 0.885714 0.838095     0.968254      0.955556     0.936508 0.938450   \n",
       "0 0.949206 0.892063 0.847619     0.958730      0.939683     0.933333 0.924537   \n",
       "0 0.965079 0.892063 0.841270     0.968254      0.939683     0.926984 0.947805   \n",
       "0 0.933333 0.869841 0.850794     0.952381      0.920635     0.933333 0.902473   \n",
       "0 0.961905 0.882540 0.841270     0.961905      0.936508     0.933333 0.942985   \n",
       "0 0.955556 0.885714 0.847619     0.965079      0.933333     0.917460 0.933771   \n",
       "\n",
       "   SVM_mcc  LDA_mcc  XGBoost_mcc  LightGBM_mcc  NN_Adam_mcc  \n",
       "0 0.811440 0.729974     0.915158      0.891056     0.872392  \n",
       "0 0.782278 0.723985     0.900340      0.828722     0.814323  \n",
       "0 0.814127 0.730662     0.920398      0.876840     0.854918  \n",
       "0 0.802772 0.709814     0.939047      0.876230     0.867546  \n",
       "0 0.830734 0.757223     0.952511      0.933517     0.905104  \n",
       "0 0.841781 0.775673     0.938365      0.909565     0.900122  \n",
       "0 0.840245 0.764091     0.952424      0.910571     0.890597  \n",
       "0 0.809190 0.780247     0.930359      0.881366     0.900504  \n",
       "0 0.824745 0.762782     0.943028      0.905803     0.900422  \n",
       "0 0.831797 0.771989     0.947891      0.900122     0.877957  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_CV_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_acc         0.944985\n",
      "SVM_acc        0.877619\n",
      "LDA_acc        0.831063\n",
      "XGBoost_acc    0.955555\n",
      "LightGBM_acc   0.927353\n",
      "NN_Adam_acc    0.917120\n",
      "RF_mcc         0.918366\n",
      "SVM_mcc        0.819566\n",
      "LDA_mcc        0.747994\n",
      "XGBoost_mcc    0.933729\n",
      "LightGBM_mcc   0.891401\n",
      "NN_Adam_mcc    0.876728\n",
      "dtype: float64\n",
      "RF_acc         0.949560\n",
      "SVM_acc        0.881145\n",
      "LDA_acc        0.838818\n",
      "XGBoost_acc    0.956261\n",
      "LightGBM_acc   0.933337\n",
      "NN_Adam_acc    0.922396\n",
      "RF_mcc         0.925210\n",
      "SVM_mcc        0.824719\n",
      "LDA_mcc        0.759811\n",
      "XGBoost_mcc    0.934874\n",
      "LightGBM_mcc   0.900497\n",
      "NN_Adam_mcc    0.884872\n",
      "dtype: float64\n",
      "RF_acc         0.949570\n",
      "SVM_acc        0.881145\n",
      "LDA_acc        0.831766\n",
      "XGBoost_acc    0.956619\n",
      "LightGBM_acc   0.931930\n",
      "NN_Adam_acc    0.917469\n",
      "RF_mcc         0.925282\n",
      "SVM_mcc        0.824457\n",
      "LDA_mcc        0.749065\n",
      "XGBoost_mcc    0.935410\n",
      "LightGBM_mcc   0.898226\n",
      "NN_Adam_mcc    0.876943\n",
      "dtype: float64\n",
      "RF_acc         0.944273\n",
      "SVM_acc        0.880791\n",
      "LDA_acc        0.837054\n",
      "XGBoost_acc    0.950973\n",
      "LightGBM_acc   0.926288\n",
      "NN_Adam_acc    0.908293\n",
      "RF_mcc         0.917321\n",
      "SVM_mcc        0.823711\n",
      "LDA_mcc        0.757254\n",
      "XGBoost_mcc    0.926894\n",
      "LightGBM_mcc   0.889818\n",
      "NN_Adam_mcc    0.864643\n",
      "dtype: float64\n",
      "RF_acc         0.943918\n",
      "SVM_acc        0.879034\n",
      "LDA_acc        0.827892\n",
      "XGBoost_acc    0.955567\n",
      "LightGBM_acc   0.925592\n",
      "NN_Adam_acc    0.913235\n",
      "RF_mcc         0.917608\n",
      "SVM_mcc        0.821489\n",
      "LDA_mcc        0.743095\n",
      "XGBoost_mcc    0.933945\n",
      "LightGBM_mcc   0.888781\n",
      "NN_Adam_mcc    0.871457\n",
      "dtype: float64\n",
      "RF_acc         0.943223\n",
      "SVM_acc        0.876561\n",
      "LDA_acc        0.832484\n",
      "XGBoost_acc    0.954860\n",
      "LightGBM_acc   0.928410\n",
      "NN_Adam_acc    0.911147\n",
      "RF_mcc         0.916152\n",
      "SVM_mcc        0.817462\n",
      "LDA_mcc        0.750235\n",
      "XGBoost_mcc    0.932950\n",
      "LightGBM_mcc   0.892956\n",
      "NN_Adam_mcc    0.868995\n",
      "dtype: float64\n",
      "RF_acc         0.940398\n",
      "SVM_acc        0.875851\n",
      "LDA_acc        0.830019\n",
      "XGBoost_acc    0.952383\n",
      "LightGBM_acc   0.926996\n",
      "NN_Adam_acc    0.915352\n",
      "RF_mcc         0.911672\n",
      "SVM_mcc        0.816546\n",
      "LDA_mcc        0.746731\n",
      "XGBoost_mcc    0.929085\n",
      "LightGBM_mcc   0.890864\n",
      "NN_Adam_mcc    0.874860\n",
      "dtype: float64\n",
      "RF_acc         0.948161\n",
      "SVM_acc        0.878325\n",
      "LDA_acc        0.831064\n",
      "XGBoost_acc    0.955924\n",
      "LightGBM_acc   0.928066\n",
      "NN_Adam_acc    0.912881\n",
      "RF_mcc         0.923150\n",
      "SVM_mcc        0.820587\n",
      "LDA_mcc        0.748279\n",
      "XGBoost_mcc    0.934475\n",
      "LightGBM_mcc   0.892523\n",
      "NN_Adam_mcc    0.870741\n",
      "dtype: float64\n",
      "RF_acc         0.947098\n",
      "SVM_acc        0.877620\n",
      "LDA_acc        0.828954\n",
      "XGBoost_acc    0.956273\n",
      "LightGBM_acc   0.928061\n",
      "NN_Adam_acc    0.918190\n",
      "RF_mcc         0.921677\n",
      "SVM_mcc        0.818943\n",
      "LDA_mcc        0.744765\n",
      "XGBoost_mcc    0.934889\n",
      "LightGBM_mcc   0.892422\n",
      "NN_Adam_mcc    0.878271\n",
      "dtype: float64\n",
      "RF_acc         0.941463\n",
      "SVM_acc        0.878674\n",
      "LDA_acc        0.831419\n",
      "XGBoost_acc    0.955208\n",
      "LightGBM_acc   0.928412\n",
      "NN_Adam_acc    0.912524\n",
      "RF_mcc         0.913113\n",
      "SVM_mcc        0.820534\n",
      "LDA_mcc        0.748928\n",
      "XGBoost_mcc    0.933337\n",
      "LightGBM_mcc   0.893119\n",
      "NN_Adam_mcc    0.871251\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ],
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(inner_CV_result.mean(axis = 0)) for inner_CV_result in all_CV_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RF_acc         0.948254\n",
       "SVM_acc        0.877460\n",
       "LDA_acc        0.832698\n",
       "XGBoost_acc    0.955556\n",
       "LightGBM_acc   0.927302\n",
       "NN_Adam_acc    0.918413\n",
       "RF_mcc         0.923428\n",
       "SVM_mcc        0.818911\n",
       "LDA_mcc        0.750644\n",
       "XGBoost_mcc    0.933952\n",
       "LightGBM_mcc   0.891379\n",
       "NN_Adam_mcc    0.878389\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf_results_inner_fold, ['Random Forest','SVM', 'LDA', *NN_labels], len(NN_params), len(classifiers)\n",
    "outer_CV_results_df.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
